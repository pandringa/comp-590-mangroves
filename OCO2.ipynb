{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-0.12.0-py2.py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: pandas in /srv/conda/envs/notebook/lib/python3.7/site-packages (0.25.3)\n",
      "Requirement already satisfied: pydap in /srv/conda/envs/notebook/lib/python3.7/site-packages (3.2.2)\n",
      "Requirement already satisfied: geopandas in /srv/conda/envs/notebook/lib/python3.7/site-packages (0.6.2)\n",
      "Collecting thredds_crawler\n",
      "  Using cached thredds_crawler-1.5.4-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pandas) (2.7.5)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pandas) (1.17.3)\n",
      "Requirement already satisfied: pytz>=2017.2 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: Webob in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pydap) (1.8.6)\n",
      "Requirement already satisfied: six>=1.4.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pydap) (1.14.0)\n",
      "Requirement already satisfied: docopt in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pydap) (0.6.2)\n",
      "Requirement already satisfied: Jinja2 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pydap) (2.11.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pydap) (4.8.2)\n",
      "Requirement already satisfied: fiona in /srv/conda/envs/notebook/lib/python3.7/site-packages (from geopandas) (1.8.6)\n",
      "Requirement already satisfied: shapely in /srv/conda/envs/notebook/lib/python3.7/site-packages (from geopandas) (1.6.4.post2)\n",
      "Requirement already satisfied: pyproj in /srv/conda/envs/notebook/lib/python3.7/site-packages (from geopandas) (1.9.6)\n",
      "Requirement already satisfied: requests in /srv/conda/envs/notebook/lib/python3.7/site-packages (from thredds_crawler) (2.22.0)\n",
      "Requirement already satisfied: lxml in /srv/conda/envs/notebook/lib/python3.7/site-packages (from thredds_crawler) (4.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from Jinja2->pydap) (1.1.1)\n",
      "Requirement already satisfied: soupsieve>=1.2 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from beautifulsoup4->pydap) (1.9.4)\n",
      "Requirement already satisfied: attrs>=17 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from fiona->geopandas) (19.3.0)\n",
      "Requirement already satisfied: click<8,>=4.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from fiona->geopandas) (7.0)\n",
      "Requirement already satisfied: cligj>=0.5 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from fiona->geopandas) (0.5.0)\n",
      "Requirement already satisfied: click-plugins>=1.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from fiona->geopandas) (1.1.1)\n",
      "Requirement already satisfied: munch in /srv/conda/envs/notebook/lib/python3.7/site-packages (from fiona->geopandas) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from requests->thredds_crawler) (2019.11.28)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from requests->thredds_crawler) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from requests->thredds_crawler) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from requests->thredds_crawler) (1.25.7)\n",
      "Installing collected packages: python-dotenv, thredds-crawler\n",
      "Successfully installed python-dotenv-0.12.0 thredds-crawler-1.5.4\n"
     ]
    }
   ],
   "source": [
    "# Install, import libraries\n",
    "import sys\n",
    "!{sys.executable} -m pip install python-dotenv pandas pydap geopandas thredds_crawler\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from pydap.client import open_url\n",
    "from pydap.cas.urs import setup_session\n",
    "\n",
    "import xarray as xr\n",
    "import requests\n",
    "import re\n",
    "\n",
    "%load_ext dotenv\n",
    "%dotenv\n",
    "from os import environ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 350 files for 2018.\n",
      "Loading dataset 0/350\n",
      "Loading dataset 1/350\n",
      "Loading dataset 2/350\n",
      "Loading dataset 3/350\n",
      "Loading dataset 4/350\n",
      "Loading dataset 5/350\n",
      "Loading dataset 6/350\n",
      "Loading dataset 7/350\n",
      "Loading dataset 8/350\n",
      "Loading dataset 9/350\n",
      "Loading dataset 10/350\n",
      "Loading dataset 11/350\n",
      "Loading dataset 12/350\n",
      "Loading dataset 13/350\n",
      "Loading dataset 14/350\n",
      "Loading dataset 15/350\n",
      "Loading dataset 16/350\n",
      "Loading dataset 17/350\n",
      "Loading dataset 18/350\n",
      "Loading dataset 19/350\n",
      "Loading dataset 20/350\n",
      "Loading dataset 21/350\n",
      "Loading dataset 22/350\n",
      "Loading dataset 23/350\n",
      "Loading dataset 24/350\n",
      "Loading dataset 25/350\n",
      "Loading dataset 26/350\n",
      "Loading dataset 27/350\n",
      "Loading dataset 28/350\n",
      "Loading dataset 29/350\n",
      "Loading dataset 30/350\n",
      "Loading dataset 31/350\n",
      "Loading dataset 32/350\n",
      "Loading dataset 33/350\n",
      "Loading dataset 34/350\n",
      "Loading dataset 35/350\n",
      "Loading dataset 36/350\n",
      "Loading dataset 37/350\n",
      "Loading dataset 38/350\n",
      "Loading dataset 39/350\n",
      "Loading dataset 40/350\n",
      "Loading dataset 41/350\n",
      "Loading dataset 42/350\n",
      "Loading dataset 43/350\n",
      "Loading dataset 44/350\n",
      "Loading dataset 45/350\n",
      "Loading dataset 46/350\n",
      "Loading dataset 47/350\n",
      "Loading dataset 48/350\n",
      "Loading dataset 49/350\n",
      "Loading dataset 50/350\n",
      "Loading dataset 51/350\n",
      "Loading dataset 52/350\n",
      "Loading dataset 53/350\n",
      "Loading dataset 54/350\n",
      "Loading dataset 55/350\n",
      "Loading dataset 56/350\n",
      "Loading dataset 57/350\n",
      "Loading dataset 58/350\n",
      "Loading dataset 59/350\n",
      "Loading dataset 60/350\n",
      "Loading dataset 61/350\n",
      "Loading dataset 62/350\n",
      "Loading dataset 63/350\n",
      "Loading dataset 64/350\n",
      "Loading dataset 65/350\n",
      "Loading dataset 66/350\n",
      "Loading dataset 67/350\n",
      "Loading dataset 68/350\n",
      "Loading dataset 69/350\n",
      "Loading dataset 70/350\n",
      "Loading dataset 71/350\n",
      "Loading dataset 72/350\n",
      "Loading dataset 73/350\n",
      "Loading dataset 74/350\n",
      "Loading dataset 75/350\n",
      "Loading dataset 76/350\n",
      "Loading dataset 77/350\n",
      "Loading dataset 78/350\n",
      "Loading dataset 79/350\n",
      "Loading dataset 80/350\n",
      "Loading dataset 81/350\n",
      "Loading dataset 82/350\n",
      "Loading dataset 83/350\n",
      "Loading dataset 84/350\n",
      "Loading dataset 85/350\n",
      "Loading dataset 86/350\n",
      "Loading dataset 87/350\n",
      "Loading dataset 88/350\n",
      "Loading dataset 89/350\n",
      "Loading dataset 90/350\n",
      "Loading dataset 91/350\n",
      "Loading dataset 92/350\n",
      "Loading dataset 93/350\n",
      "Loading dataset 94/350\n",
      "Loading dataset 95/350\n",
      "Loading dataset 96/350\n",
      "Loading dataset 97/350\n",
      "Loading dataset 98/350\n",
      "Loading dataset 99/350\n",
      "Loading dataset 100/350\n",
      "Loading dataset 101/350\n",
      "Loading dataset 102/350\n",
      "Loading dataset 103/350\n",
      "Loading dataset 104/350\n",
      "Loading dataset 105/350\n",
      "Loading dataset 106/350\n",
      "Loading dataset 107/350\n",
      "Loading dataset 108/350\n",
      "Loading dataset 109/350\n",
      "Loading dataset 110/350\n",
      "Loading dataset 111/350\n",
      "Loading dataset 112/350\n",
      "Loading dataset 113/350\n",
      "Loading dataset 114/350\n",
      "Loading dataset 115/350\n",
      "Loading dataset 116/350\n",
      "Loading dataset 117/350\n",
      "Loading dataset 118/350\n",
      "Loading dataset 119/350\n",
      "Loading dataset 120/350\n",
      "Loading dataset 121/350\n",
      "Loading dataset 122/350\n",
      "Loading dataset 123/350\n",
      "Loading dataset 124/350\n",
      "Loading dataset 125/350\n",
      "Loading dataset 126/350\n",
      "Loading dataset 127/350\n",
      "Loading dataset 128/350\n",
      "Loading dataset 129/350\n",
      "Loading dataset 130/350\n",
      "Loading dataset 131/350\n",
      "Loading dataset 132/350\n",
      "Loading dataset 133/350\n",
      "Loading dataset 134/350\n",
      "Loading dataset 135/350\n",
      "Loading dataset 136/350\n",
      "Loading dataset 137/350\n",
      "Loading dataset 138/350\n",
      "Loading dataset 139/350\n",
      "Loading dataset 140/350\n",
      "Loading dataset 141/350\n",
      "Loading dataset 142/350\n",
      "Loading dataset 143/350\n",
      "Loading dataset 144/350\n",
      "Loading dataset 145/350\n",
      "Loading dataset 146/350\n",
      "Loading dataset 147/350\n",
      "Loading dataset 148/350\n",
      "Loading dataset 149/350\n",
      "Loading dataset 150/350\n",
      "Loading dataset 151/350\n",
      "Loading dataset 152/350\n",
      "Loading dataset 153/350\n",
      "Loading dataset 154/350\n",
      "Loading dataset 155/350\n",
      "Loading dataset 156/350\n",
      "Loading dataset 157/350\n",
      "Loading dataset 158/350\n",
      "Loading dataset 159/350\n",
      "Loading dataset 160/350\n",
      "Loading dataset 161/350\n",
      "Loading dataset 162/350\n",
      "Loading dataset 163/350\n",
      "Loading dataset 164/350\n",
      "Loading dataset 165/350\n",
      "Loading dataset 166/350\n",
      "Loading dataset 167/350\n",
      "Loading dataset 168/350\n",
      "Loading dataset 169/350\n",
      "Loading dataset 170/350\n",
      "Loading dataset 171/350\n",
      "Loading dataset 172/350\n",
      "Loading dataset 173/350\n",
      "Loading dataset 174/350\n",
      "Loading dataset 175/350\n",
      "Loading dataset 176/350\n",
      "Loading dataset 177/350\n",
      "Loading dataset 178/350\n",
      "Loading dataset 179/350\n",
      "Loading dataset 180/350\n",
      "Loading dataset 181/350\n",
      "Loading dataset 182/350\n",
      "Loading dataset 183/350\n",
      "Loading dataset 184/350\n",
      "Loading dataset 185/350\n",
      "Loading dataset 186/350\n",
      "Loading dataset 187/350\n",
      "Loading dataset 188/350\n",
      "Loading dataset 189/350\n",
      "Loading dataset 190/350\n",
      "Loading dataset 191/350\n",
      "Loading dataset 192/350\n",
      "Loading dataset 193/350\n",
      "Loading dataset 194/350\n",
      "Loading dataset 195/350\n",
      "Loading dataset 196/350\n",
      "Loading dataset 197/350\n",
      "Loading dataset 198/350\n",
      "Loading dataset 199/350\n",
      "Loading dataset 200/350\n",
      "Loading dataset 201/350\n",
      "Loading dataset 202/350\n",
      "Loading dataset 203/350\n",
      "Loading dataset 204/350\n",
      "Loading dataset 205/350\n",
      "Loading dataset 206/350\n",
      "Loading dataset 207/350\n",
      "Loading dataset 208/350\n",
      "Loading dataset 209/350\n",
      "Loading dataset 210/350\n",
      "Loading dataset 211/350\n",
      "Loading dataset 212/350\n",
      "Loading dataset 213/350\n",
      "Loading dataset 214/350\n",
      "Loading dataset 215/350\n",
      "Loading dataset 216/350\n",
      "Loading dataset 217/350\n",
      "Loading dataset 218/350\n",
      "Loading dataset 219/350\n",
      "Loading dataset 220/350\n",
      "Loading dataset 221/350\n",
      "Loading dataset 222/350\n",
      "Loading dataset 223/350\n",
      "Loading dataset 224/350\n",
      "Loading dataset 225/350\n",
      "Loading dataset 226/350\n",
      "Loading dataset 227/350\n",
      "Loading dataset 228/350\n",
      "Loading dataset 229/350\n",
      "Loading dataset 230/350\n",
      "Loading dataset 231/350\n",
      "Loading dataset 232/350\n",
      "Loading dataset 233/350\n",
      "Loading dataset 234/350\n",
      "Loading dataset 235/350\n",
      "Loading dataset 236/350\n",
      "Loading dataset 237/350\n",
      "Loading dataset 238/350\n",
      "Loading dataset 239/350\n",
      "Loading dataset 240/350\n",
      "Loading dataset 241/350\n",
      "Loading dataset 242/350\n",
      "Loading dataset 243/350\n",
      "Loading dataset 244/350\n",
      "Loading dataset 245/350\n",
      "Loading dataset 246/350\n",
      "Loading dataset 247/350\n",
      "Loading dataset 248/350\n",
      "Loading dataset 249/350\n",
      "Loading dataset 250/350\n",
      "Loading dataset 251/350\n",
      "Loading dataset 252/350\n",
      "Loading dataset 253/350\n",
      "Loading dataset 254/350\n",
      "Loading dataset 255/350\n",
      "Loading dataset 256/350\n",
      "Loading dataset 257/350\n",
      "Loading dataset 258/350\n",
      "Loading dataset 259/350\n",
      "Loading dataset 260/350\n",
      "Loading dataset 261/350\n",
      "Loading dataset 262/350\n",
      "Loading dataset 263/350\n",
      "Loading dataset 264/350\n",
      "Loading dataset 265/350\n",
      "Loading dataset 266/350\n",
      "Loading dataset 267/350\n",
      "Loading dataset 268/350\n",
      "Loading dataset 269/350\n",
      "Loading dataset 270/350\n",
      "Loading dataset 271/350\n",
      "Loading dataset 272/350\n",
      "Loading dataset 273/350\n",
      "Loading dataset 274/350\n",
      "Loading dataset 275/350\n",
      "Loading dataset 276/350\n",
      "Loading dataset 277/350\n",
      "Loading dataset 278/350\n",
      "Loading dataset 279/350\n",
      "Loading dataset 280/350\n",
      "Loading dataset 281/350\n",
      "Loading dataset 282/350\n",
      "Loading dataset 283/350\n",
      "Loading dataset 284/350\n",
      "Loading dataset 285/350\n",
      "Loading dataset 286/350\n",
      "Loading dataset 287/350\n",
      "Loading dataset 288/350\n",
      "Loading dataset 289/350\n",
      "Loading dataset 290/350\n",
      "Loading dataset 291/350\n",
      "Loading dataset 292/350\n",
      "Loading dataset 293/350\n",
      "Loading dataset 294/350\n",
      "Loading dataset 295/350\n",
      "Loading dataset 296/350\n",
      "Loading dataset 297/350\n",
      "Loading dataset 298/350\n",
      "Loading dataset 299/350\n",
      "Loading dataset 300/350\n",
      "Loading dataset 301/350\n",
      "Loading dataset 302/350\n",
      "Loading dataset 303/350\n",
      "Loading dataset 304/350\n",
      "Loading dataset 305/350\n",
      "Loading dataset 306/350\n",
      "Loading dataset 307/350\n",
      "Loading dataset 308/350\n",
      "Loading dataset 309/350\n",
      "Loading dataset 310/350\n",
      "Loading dataset 311/350\n",
      "Loading dataset 312/350\n",
      "Loading dataset 313/350\n",
      "Loading dataset 314/350\n",
      "Loading dataset 315/350\n",
      "Loading dataset 316/350\n",
      "Loading dataset 317/350\n",
      "Loading dataset 318/350\n",
      "Loading dataset 319/350\n",
      "Loading dataset 320/350\n",
      "Loading dataset 321/350\n",
      "Loading dataset 322/350\n",
      "Loading dataset 323/350\n",
      "Loading dataset 324/350\n",
      "Loading dataset 325/350\n",
      "Loading dataset 326/350\n",
      "Loading dataset 327/350\n",
      "Loading dataset 328/350\n",
      "Loading dataset 329/350\n",
      "Loading dataset 330/350\n",
      "Loading dataset 331/350\n",
      "Loading dataset 332/350\n",
      "Loading dataset 333/350\n",
      "Loading dataset 334/350\n",
      "Loading dataset 335/350\n",
      "Loading dataset 336/350\n",
      "Loading dataset 337/350\n",
      "Loading dataset 338/350\n",
      "Loading dataset 339/350\n",
      "Loading dataset 340/350\n",
      "Loading dataset 341/350\n",
      "Loading dataset 342/350\n",
      "Loading dataset 343/350\n",
      "Loading dataset 344/350\n",
      "Loading dataset 345/350\n",
      "Loading dataset 346/350\n",
      "Loading dataset 347/350\n",
      "Loading dataset 348/350\n",
      "Loading dataset 349/350\n",
      "Done. Loaded 1688.875717163086 MB into a dataset.\n"
     ]
    }
   ],
   "source": [
    "## Run this if you don't have a .nc file to work with\n",
    "\n",
    "base_url = \"https://oco2.gesdisc.eosdis.nasa.gov\"\n",
    "def list_urls(year):\n",
    "    r = requests.get(f\"https://oco2.gesdisc.eosdis.nasa.gov/opendap/OCO2_L2_Lite_FP.9r/{year}/catalog.xml\")\n",
    "    paths = re.findall(\"ID=\\\"(/opendap/hyrax/OCO2_L2_Lite_FP.9r/\\d{4}/.*.nc4)\\\"\", r.text)\n",
    "    print(f\"Found {len(paths)} files for {year}.\")\n",
    "    return paths\n",
    "\n",
    "## Based on code from http://xarray.pydata.org/en/stable/io.html\n",
    "def read_datasets(files, dim, transform_func=None):\n",
    "    prog_ = 0\n",
    "    session = setup_session(environ.get(\"EARTHDATA_USER\"), environ.get(\"EARTHDATA_PASS\"), check_url=base_url+files[0])\n",
    "    def process_one_path(path,i):\n",
    "        print(f\"Loading dataset {i}/{len(files)}\")\n",
    "        # use a context manager, to ensure the file gets closed after use\n",
    "        with xr.backends.PydapDataStore.open(path, session=session) as store:\n",
    "            with xr.open_dataset(store) as ds:\n",
    "                # transform_func should do some sort of selection or aggregation\n",
    "                # aggregation\n",
    "                if transform_func is not None:\n",
    "                    ds = transform_func(ds)\n",
    "                ds.load()\n",
    "                return ds\n",
    "\n",
    "    paths = sorted(files) # TODO use Glob\n",
    "    datasets = [process_one_path(base_url+p,i) for i,p in enumerate(paths)]\n",
    "    \n",
    "    return xr.concat(datasets, dim)\n",
    "\n",
    "# Method to reshape one dataset\n",
    "def reshape_dataset(ds):\n",
    "    return ds[[ 'sounding_id', 'latitude', 'longitude', 'time', 'xco2' ]]\n",
    "\n",
    "# here we suppose we only care about the combined mean of each file;\n",
    "# you might also use indexing operations like .sel to subset datasets\n",
    "combined = read_datasets(list_urls(2018), dim='sounding_id', transform_func=reshape_dataset)\n",
    "\n",
    "print(f\"Done. Loaded {combined.nbytes * (2 ** -20)} MB into a dataset.\")\n",
    "\n",
    "combined.to_netcdf('2018_soundings.nc')\n",
    "\n",
    "combined = combined.set_index(sounding_id=['latitude', 'longitude', 'time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>&lt;xarray.Dataset&gt;\n",
       "Dimensions:      (sounding_id: 63227343)\n",
       "Coordinates:\n",
       "  * sounding_id  (sounding_id) MultiIndex\n",
       "  - latitude     (sounding_id) float64 -80.31 -82.25 -84.1 ... 44.03 44.07 44.08\n",
       "  - longitude    (sounding_id) float64 -9.986 -20.53 -38.81 ... 42.01 42.03\n",
       "  - time         (sounding_id) datetime64[ns] 2019-01-01T00:21:25.336017664 ... 2020-01-21T10:01:06.082991616\n",
       "Data variables:\n",
       "    xco2         (sounding_id) float32 ...\n",
       "Attributes:\n",
       "    identifier_product_doi:            10.5067/W8QGIYNKS3JC\n",
       "    identifier_product_doi_authority:  http://dx.doi.org/\n",
       "    filter_function:                   oco2_xco2_quality_flag_b9\n",
       "    bc_function:                       oco2_bias_correct_b9\n",
       "    warn_level_function:               oco2_warn_levels_b8\n",
       "    Bias_Correction_land:              XCO2_Bias_Corrected = (XCO2_Raw + 0.90...\n",
       "    Bias_Correction_oceanGL:           XCO2_Bias_Corrected = (XCO2_Raw + 0.24...\n",
       "    Footprint_bias_land:               Assumed footprint biases in xco2 [ppm]...\n",
       "    Footprint_bias_oceanGL:            Assumed footprint biases in xco2 [ppm]...\n",
       "    Bias_Uncertainty:                  Bias correction parameter uncertaintie...\n",
       "    Note_regarding_bias_correction:    There is some uncertainty in not only ...\n",
       "    Platform:                          OCO-2\n",
       "    Sensor:                            OCO-2\n",
       "    title:                             ACOS L2 Lite Output\n",
       "    BuildId:                           B8.1.00\n",
       "    filtering_state:                   Filtered with oco2_lite_file_prefilter...\n",
       "    creation_date:                     Mar 2019\n",
       "    contact:                           Chris O&#x27;Dell: odell@atmos.colostate.edu</pre>"
      ],
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:      (sounding_id: 63227343)\n",
       "Coordinates:\n",
       "  * sounding_id  (sounding_id) MultiIndex\n",
       "  - latitude     (sounding_id) float64 -80.31 -82.25 -84.1 ... 44.03 44.07 44.08\n",
       "  - longitude    (sounding_id) float64 -9.986 -20.53 -38.81 ... 42.01 42.03\n",
       "  - time         (sounding_id) datetime64[ns] 2019-01-01T00:21:25.336017664 ... 2020-01-21T10:01:06.082991616\n",
       "Data variables:\n",
       "    xco2         (sounding_id) float32 ...\n",
       "Attributes:\n",
       "    identifier_product_doi:            10.5067/W8QGIYNKS3JC\n",
       "    identifier_product_doi_authority:  http://dx.doi.org/\n",
       "    filter_function:                   oco2_xco2_quality_flag_b9\n",
       "    bc_function:                       oco2_bias_correct_b9\n",
       "    warn_level_function:               oco2_warn_levels_b8\n",
       "    Bias_Correction_land:              XCO2_Bias_Corrected = (XCO2_Raw + 0.90...\n",
       "    Bias_Correction_oceanGL:           XCO2_Bias_Corrected = (XCO2_Raw + 0.24...\n",
       "    Footprint_bias_land:               Assumed footprint biases in xco2 [ppm]...\n",
       "    Footprint_bias_oceanGL:            Assumed footprint biases in xco2 [ppm]...\n",
       "    Bias_Uncertainty:                  Bias correction parameter uncertaintie...\n",
       "    Note_regarding_bias_correction:    There is some uncertainty in not only ...\n",
       "    Platform:                          OCO-2\n",
       "    Sensor:                            OCO-2\n",
       "    title:                             ACOS L2 Lite Output\n",
       "    BuildId:                           B8.1.00\n",
       "    filtering_state:                   Filtered with oco2_lite_file_prefilter...\n",
       "    creation_date:                     Mar 2019\n",
       "    contact:                           Chris O'Dell: odell@atmos.colostate.edu"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Run this if you already have a file\n",
    "\n",
    "combined = xr.open_dataset('2019_20_soundings.nc').set_index(sounding_id=['latitude', 'longitude', 'time'])\n",
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unc = [-79.0558,35.9132]\n",
    "tol = 1\n",
    "result = None\n",
    "\n",
    "try:\n",
    "    result = combined.sel(\n",
    "        longitude=slice(unc[0]-tol, unc[0]+tol),\n",
    "        latitude=slice(unc[1]-tol, unc[1]+tol)\n",
    "        )\n",
    "except KeyError as e:\n",
    "    result = f\"Not found: {e}\"\n",
    "    \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.where(combined.latitude <)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://oco2.gesdisc.eosdis.nasa.gov/opendap/OCO2_L2_Lite_FP.9r/\"\n",
    "session = setup_session(environ.get(\"EARTHDATA_USER\"), environ.get(\"EARTHDATA_PASS\"), check_url=base_url+datasets[0])\n",
    "# use a context manager, to ensure the file gets closed after use\n",
    "store = xr.backends.PydapDataStore.open(base_url+datasets[0], session=session)\n",
    "ds = xr.open_dataset(store)\n",
    "\n",
    "ds = (ds[[ 'sounding_id', 'latitude', 'longitude', 'time', 'xco2' ]]\n",
    "   .set_index(sounding_id=['latitude', 'longitude', 'time']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "unstacked = None;\n",
    "for n in [100]:\n",
    "    start = time.time()\n",
    "    print(f\"Unstacking {n} rows\");\n",
    "    unstacked = ds.isel(sounding_id=slice(0,n)).unstack()\n",
    "    print(f\"Elapsed for {n} time: {time.time()-start}s\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.nbytes * (2 ** -20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unstacked.nbytes * (2 ** -20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6487814523279667"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.nbytes * (2 ** -30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
